import pickle
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from konlpy.tag import Okt, Komoran
from sklearn.preprocessing import MultiLabelBinarizer #ë©€í‹°ë¡œ ìˆ˜ì •
from keras.utils import to_categorical
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import re
from sklearn.utils import resample  # âœ… ì¶”ê°€
import matplotlib.pyplot as plt     # âœ… ì¶”ê°€
import seaborn as sns               # âœ… ì¶”ê°€
from collections import Counter     # âœ… ì¶”ê°€
import matplotlib
matplotlib.rc('font', family='Malgun Gothic')  # ìœˆë„ìš°ì¼ ê²½ìš°
matplotlib.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€

ALLOWED_GENRES = [
    'Reality TV', 'SF', 'ê°€ì¡±', 'ê³µí¬', 'ë‹¤íë©˜í„°ë¦¬',
    'ë“œë¼ë§ˆ', 'ë¡œë§¨ìŠ¤', 'ë²”ì£„', 'ìŠ¤í¬ì¸ ', 'ì•¡ì…˜', 'ì—­ì‚¬', 'ì½”ë¯¸ë””', 'íŒíƒ€ì§€'
]
# âœ… ì˜¤ë²„ìƒ˜í”Œë§ í•¨ìˆ˜ ì •ì˜
from collections import Counter

def oversample_by_individual_label(df, allowed_genres, genre_col='genre'):
    # 1. ì¥ë¥´ë³„ ë“±ì¥ íšŸìˆ˜ ì„¸ê¸°
    all_labels = [g for sublist in df[genre_col] for g in sublist]
    label_counts = Counter(all_labels)

    # 2. ëª©í‘œ ë“±ì¥ íšŸìˆ˜ (ê°€ì¥ ë§ì€ ì¥ë¥´ ìˆ˜ë¡œ ë§ì¶¤)
    target_count = max(label_counts[g] for g in allowed_genres)

    # 3. ì¥ë¥´ë³„ë¡œ ë¶€ì¡±í•œ ë§Œí¼ ë³µì œ
    dfs = [df]  # ì›ë³¸ í¬í•¨
    for genre in allowed_genres:
        genre_df = df[df[genre_col].apply(lambda x: genre in x)]
        count = label_counts[genre]
        if count < target_count:
            needed = target_count - count
            sampled = resample(genre_df, replace=True, n_samples=needed, random_state=42)
            dfs.append(sampled)

    df_balanced = pd.concat(dfs).reset_index(drop=True)
    return df_balanced

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('./crawling_data/data.csv')
# í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µ í–‰ ì œê±° ë° ì¸ë±ìŠ¤ ì¬ì •ë ¬
df.drop_duplicates(inplace=True)
df.reset_index(drop=True, inplace=True)
df = df.dropna(subset=['title', 'synopsis', 'genre']).reset_index(drop=True)


def clean_genres(genres):
    if isinstance(genres, str):  # í˜¹ì‹œ ë¬¸ìì—´ì´ë©´ split
        genres = [g.strip() for g in genres.split(',') if g.strip() != '']
    return [g for g in genres if g in ALLOWED_GENRES]


# --- ì¥ë¥´ ì „ì²˜ë¦¬ ---
df['genre'] = df['genre'].fillna('').apply(clean_genres)
df['synopsis'] = df['synopsis'].fillna('')

# 2. í…ìŠ¤íŠ¸ & ì¥ë¥´ ì„¤ì •
X = df['synopsis']
Y = df['genre']
titles = df['title']  # âœ… ì¶”ê°€

# --- X, Y í•©ì³ì„œ DataFrame ë§Œë“¤ê¸° (ì˜¤ë²„ìƒ˜í”Œë§ í•¨ìˆ˜ëŠ” df í•„ìš”) ---
df_xy = pd.DataFrame({'title': titles, 'synopsis': X, 'genre': Y})  # âœ… 'title' í¬í•¨

# ğŸ”¸ ì˜¤ë²„ìƒ˜í”Œë§ ì „ ì¹´ìš´íŠ¸ ê³„ì‚°
before_counts = Counter([g for genres in df_xy['genre'] for g in genres])

# âœ… ì˜¤ë²„ìƒ˜í”Œë§ ì ìš© (ê°œë³„ ì¥ë¥´ ê¸°ì¤€)
df_xy = oversample_by_individual_label(df_xy, ALLOWED_GENRES)

# ğŸ”¸ ì˜¤ë²„ìƒ˜í”Œë§ í›„ ì¹´ìš´íŠ¸ ê³„ì‚°
after_counts = Counter([g for genres in df_xy['genre'] for g in genres])

# ğŸ”¸ ì •ë ¬ ê¸°ì¤€: ì˜¤ë²„ìƒ˜í”Œë§ í›„ ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ
sorted_genres = sorted(after_counts, key=after_counts.get, reverse=True)

# ğŸ”¸ íˆíŠ¸ë§µìš© ë°ì´í„°í”„ë ˆì„ êµ¬ì„±
heatmap_df = pd.DataFrame({
    'ì˜¤ë²„ìƒ˜í”Œë§ ì „': [before_counts[g] for g in sorted_genres],
    'ì˜¤ë²„ìƒ˜í”Œë§ í›„': [after_counts[g] for g in sorted_genres]
}, index=sorted_genres)

# ğŸ”¸ íˆíŠ¸ë§µ ê·¸ë¦¬ê¸°
# ğŸ”¸ íˆíŠ¸ë§µ ê·¸ë¦¬ê¸° (í‘ë°± ìŠ¤íƒ€ì¼)
plt.figure(figsize=(6, 8))
sns.heatmap(
    heatmap_df,
    annot=True,
    fmt="d",
    cmap="Greys",          # âš« í‘ë°± ê³„ì—´ ì»¬ëŸ¬ë§µ
    linewidths=1,          # ğŸ”² ì…€ ê²½ê³„ ê°•ì¡°
    linecolor='black',
    cbar=False             # ì»¬ëŸ¬ ë°” ì œê±°
)
plt.title("ì¥ë¥´ë³„ ë°ì´í„° ë¶„í¬ (ì˜¤ë²„ìƒ˜í”Œë§ ì „ vs í›„)")
plt.xlabel("ë‹¨ê³„")
plt.ylabel("ì¥ë¥´")
plt.tight_layout()

# ğŸ”¸ ì´ë¯¸ì§€ ì €ì¥
plt.savefig("oversampling_heatmap.png")
plt.show()

# --- ğŸ“Š ìˆ˜ì¹˜ í¬í•¨ëœ ë§‰ëŒ€ ê²¹ì¹¨ ê·¸ë˜í”„ ---
before = [before_counts[g] for g in sorted_genres]
after = [after_counts[g] for g in sorted_genres]
x = np.arange(len(sorted_genres))
bar_width = 0.6

plt.figure(figsize=(10, 6))
# íšŒìƒ‰: ì˜¤ë²„ìƒ˜í”Œë§ í›„
bars2 = plt.bar(x, after, width=bar_width, color='lightgray', label='ì˜¤ë²„ìƒ˜í”Œë§ í›„')
# ê²€ì€ìƒ‰: ì˜¤ë²„ìƒ˜í”Œë§ ì „
bars1 = plt.bar(x, before, width=bar_width, color='black', label='ì˜¤ë²„ìƒ˜í”Œë§ ì „')



# ìˆ˜ì¹˜ ì¶”ê°€
for i in range(len(x)):
    # ì˜¤ë²„ìƒ˜í”Œë§ ì „ (ê²€ì • ìœ„)
    plt.text(x[i], before[i] + 500, f'{before[i]:,}', color='black', ha='center', va='bottom', fontsize=8)
    # ì˜¤ë²„ìƒ˜í”Œë§ í›„ (íšŒìƒ‰ ìœ„)
    plt.text(x[i], after[i] + 500, f'{after[i]:,}', color='black', ha='center', va='bottom', fontsize=8)

plt.xticks(x, sorted_genres, rotation=45, ha='right')
plt.ylabel('ìƒ˜í”Œ ìˆ˜')
plt.title('ì¥ë¥´ë³„ ë°ì´í„° ë¶„í¬ (ì˜¤ë²„ìƒ˜í”Œë§ ì „ vs í›„)', fontsize=14, fontweight='bold')
plt.legend()
plt.tight_layout()
plt.savefig("oversampling_bar_comparison_annotated.png", dpi=300)
plt.show()


# --- ë‹¤ì‹œ ë¶„ë¦¬ ---
X = df_xy['synopsis']
Y = df_xy['genre']

has_korean = X.apply(lambda x: bool(re.search('[ê°€-í£]', x)))
X = X[has_korean].reset_index(drop=True)
Y = Y[has_korean].reset_index(drop=True)

# 3. ë©€í‹° ë¼ë²¨ ì¸ì½”ë”©
mlb = MultiLabelBinarizer()
multi_hot_y = mlb.fit_transform(Y)

# ì €ì¥
with open('./models/encoder_multilabel.pickle', 'wb') as f:
    pickle.dump(mlb, f)

print(multi_hot_y[:5])
print("ì „ì²´ ì¥ë¥´ ëª©ë¡:", mlb.classes_)

# 4. í˜•íƒœì†Œ ë¶„ì„ê¸° ì¤€ë¹„
okt = Okt()
komoran = Komoran()

# 5. í…ìŠ¤íŠ¸ ì •ì œ ë° í˜•íƒœì†Œ ë¶„ì„
for i in range(len(X)):
    X[i] = re.sub('[^ê°€-í£]', ' ', X[i])
    X[i] = okt.morphs(X[i], stem=True)
    if i % 500 == 0:
        print(f"{i}ë²ˆì§¸ ì²˜ë¦¬ ì¤‘...")


# 6. ë¶ˆìš©ì–´ ì œê±°
for idx, sentence in enumerate(X):
    words = []
    for word in sentence:
        if len(word) > 1:
            words.append(word)
    X[idx] = ' '.join(words)

print("ì „ì²˜ë¦¬ í›„ ì¼ë¶€ ë¬¸ì¥:")
print(X[:5])

# 7. í† í¬ë‚˜ì´ì €
token = Tokenizer()
token.fit_on_texts(X)
tokened_x = token.texts_to_sequences(X)
print(tokened_x[:3])

# ë‹¨ì–´ ìˆ˜
wordsize = len(token.word_index) + 1
print("ë‹¨ì–´ ì‚¬ì „ í¬ê¸°:", wordsize)

# ìµœëŒ€ ê¸¸ì´
max_len = 0
for sentence in tokened_x:
    if max_len < len(sentence):
        max_len = len(sentence)
print("ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´:", max_len)

# í† í¬ë‚˜ì´ì € ì €ì¥
with open('./models/token_max_{}.pickle'.format(max_len), 'wb') as f:
    pickle.dump(token, f)

# ì‹œí€€ìŠ¤ íŒ¨ë”©
x_pad = pad_sequences(tokened_x, maxlen=max_len)
print("íŒ¨ë”© ê²°ê³¼:", x_pad.shape)

df_xy = pd.DataFrame({'title': df_xy['title'], 'synopsis': X, 'genre': Y})
df_xy = df_xy[
    (df_xy['title'].astype(str).str.strip() != '') &
    (df_xy['synopsis'].astype(str).str.strip() != '') &
    (df_xy['genre'].apply(lambda g: isinstance(g, list) and len(g) > 0))
].reset_index(drop=True)

# ë‹¤ì‹œ X, Y, x_pad, y ì¬ì •ì˜
X = df_xy['synopsis']
Y = df_xy['genre']
x_pad = x_pad[df_xy.index]
multi_hot_y = mlb.transform(Y)

# 8. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬
x_train, x_test, y_train, y_test = train_test_split(x_pad, multi_hot_y, test_size=0.1, random_state=42)
print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)

# 9. ì €ì¥
np.save('./crawling_data/title_x_train_wordsize{}'.format(wordsize), x_train)
np.save('./crawling_data/title_x_test_wordsize{}'.format(wordsize), x_test)
np.save('./crawling_data/title_y_train_wordsize{}'.format(wordsize), y_train)
np.save('./crawling_data/title_y_test_wordsize{}'.format(wordsize), y_test)

